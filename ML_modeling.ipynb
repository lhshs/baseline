{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value count & unique & Null Count\n",
    "\n",
    "for i in df.columns:\n",
    "    print('\\33[103m', i, '\\33[0m')\n",
    "    print(df[i].value_counts())\n",
    "    uu = str(df[i].unique())\n",
    "    print('\\33[91m' + uu +  '\\033[0m')\n",
    "    print('\\33[94m' + 'Null Count :' + '\\033[0m', df[i].isnull().sum())\n",
    "    print('üåà')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object, float type Íµ¨Î∂Ñ \n",
    "type_lst = dict({'Object': [], 'Float64' : []})\n",
    "o_lst = []\n",
    "f_lst = []\n",
    "\n",
    "for i in dropout:\n",
    "    if dropout[i].dtype == 'O':\n",
    "        o_lst.append(i)\n",
    "    else:\n",
    "        f_lst.append(i)\n",
    "\n",
    "type_lst['Object'] = o_lst\n",
    "type_lst['Float64'] = f_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical plotly histogram\n",
    "\n",
    "cnt = -1\n",
    "\n",
    "for col in df_obj.columns:\n",
    "    cnt += 1\n",
    "    tt = ['title_names']\n",
    "    fig = px.histogram(df, x=col, text_auto=True, color_discrete_sequence=['chocolate'], width=800, height=400)\n",
    "    fig.update_layout(bargap=0.2, title=tt[cnt])\n",
    "    fig.show()\n",
    "\n",
    "#####\n",
    "\n",
    "# categorical histogram\n",
    "\n",
    "for col in df[['Sex', 'Ticket', 'Cabin', 'Embarked']].columns:\n",
    "    fig = sns.histplot(df, x=col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical plotly boxplot & describe\n",
    "\n",
    "cnt = -1\n",
    "\n",
    "for col in df_num.columns:\n",
    "    cnt += 1\n",
    "    tt = ['title_names']\n",
    "    fig = px.box(df, x=col, color_discrete_sequence=['maroon'], width=800, height=400)\n",
    "    fig.update_layout(bargap=0.2, title=tt[cnt])\n",
    "    fig.show()\n",
    "    print(df[a].describe())\n",
    "    print()\n",
    "    print('üëª')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≤∞Ï∏°Ïπò ÎπÑÏú®Î≥ÑÎ°ú ÎÑ£Í∏∞ \n",
    "import random\n",
    "\n",
    "ratio_fill = df.replace('X', np.NaN)   # To NaN\n",
    "\n",
    "nan_value = list(ratio_fill[ratio_fill[''].isnull()].index)                    # NaN Í∞í index \n",
    "select_nan_value = random.sample(nan_value, k=int(len(nan_value)*0.6))           # NaN Í∞íÏùò 60% ÏÑ†ÌÉù\n",
    "\n",
    "df.loc[fill_nan_value][['column_name']] = df.loc[fill_nan_value][['column_name']].fillna('M') \n",
    "df['column_name'] = df['column_name'].fillna('F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_TV</th>\n",
       "      <th>0_ÎÉâÏû•Í≥†</th>\n",
       "      <th>0_ÎØπÏÑú</th>\n",
       "      <th>0_ÏÑ†ÌíçÍ∏∞</th>\n",
       "      <th>0_Ï†ÑÏûêÎ†åÏßÄ</th>\n",
       "      <th>0_Ïª¥Ìì®ÌÑ∞</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_TV  0_ÎÉâÏû•Í≥†  0_ÎØπÏÑú  0_ÏÑ†ÌíçÍ∏∞  0_Ï†ÑÏûêÎ†åÏßÄ  0_Ïª¥Ìì®ÌÑ∞\n",
       "0     1      0     0      0       0      0\n",
       "1     0      1     0      0       0      0\n",
       "2     0      0     0      0       1      0\n",
       "3     0      0     0      0       0      1\n",
       "4     0      0     0      1       0      0\n",
       "5     0      0     0      1       0      0\n",
       "6     0      0     1      0       0      0\n",
       "7     0      0     1      0       0      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=['TV','ÎÉâÏû•Í≥†','Ï†ÑÏûêÎ†åÏßÄ','Ïª¥Ìì®ÌÑ∞','ÏÑ†ÌíçÍ∏∞','ÏÑ†ÌíçÍ∏∞','ÎØπÏÑú','ÎØπÏÑú']\n",
    "\n",
    "# Label Encoding\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(sample)\n",
    "\n",
    "# One-Hot Encoding\n",
    "# 2Ï∞®Ïõê ndarrayÎ°ú Î≥ÄÌôò ÌõÑ Ï†ÅÏö©\n",
    "items = np.array(sample).reshape(-1, 1)\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(sample)\n",
    "oh_labels = oh_encoder.transform(sample)\n",
    "# OneHotEncoderÎ°ú Î≥ÄÌôòÌïú Í≤∞Í≥ºÎäî Ìù¨ÏÜåÌñâÎ†¨(Sparse Matrix)Ïù¥ÎØÄÎ°ú toarray()Î•º Ïù¥Ïö©ÌïòÏó¨ Î∞ÄÏßë ÌñâÎ†¨(Dense Matrix)Î°ú Î≥ÄÌôò.\n",
    "oh_labels.toarray()\n",
    "\n",
    "# get_dummies\n",
    "df = pd.DataFrame(sample)\n",
    "pd.get_dummies(df, columns=[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \n",
    "y = \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=777)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "   # Standardization _ Standard\n",
    "   st_scaler = StandardScaler()\n",
    "   st_scaled = st_scaler.fit_transform(X_train[[col]])\n",
    "   X_train[[col]] = st_scaled\n",
    "\n",
    "   # Normalization _ MinMax\n",
    "   mm_scaler = MinMaxScaler()\n",
    "   mm_scaled = mm_scaler.fit_transform(X_train[[col]])\n",
    "   X_train[[col]] = mm_scaled\n",
    "\n",
    "   # Same Scaler to validation Data\n",
    "   st_scaled_t = st_scaler.transform(X_val[[col]])\n",
    "   X_val[[col]] = st_scaled_t\n",
    "   mm_scaled_t = mm_scaler.transform(X_val[[col]])\n",
    "   X_val[[col]] = mm_scaled_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Load\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "xgb = xgb.XGBClassifier()\n",
    "lgb = lgb.LGBMClassifier()\n",
    "\n",
    "# Training \n",
    "dt.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "dt_pred = dt.predict(X_val)\n",
    "rf_pred = rf.predict(X_val)\n",
    "xgb_pred = xgb.predict(X_val)\n",
    "lgb_pred = lgb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lst = ['Decision Tree', 'Random Forest', 'XGBoost', 'LightGBM']\n",
    "pred_lst = [dt_pred, rf_pred, xgb_pred, lgb_pred]\n",
    "parm = [None, 'micro', 'macro', 'weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, pred in zip(model_lst, pred_lst):\n",
    "    print('üîª','\\33[91m' + m + '\\033[0m', 'üîª')\n",
    "    accuracy = accuracy_score(y_val, pred)\n",
    "    precision = precision_score(y_val, pred)\n",
    "    recall = recall_score(y_val, pred)\n",
    "    f1 = f1_score(y_val, pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print()\n",
    "\n",
    "    print('='*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics average Ï∂îÍ∞Ä\n",
    "\n",
    "for m, pred in zip(model_lst, pred_lst):\n",
    "    print('\\33[91m' + m + '\\033[0m')\n",
    "    for i in parm:\n",
    "        accuracy = accuracy_score(y_val, pred)\n",
    "        precision = precision_score(y_val, pred, average=i)\n",
    "        recall = recall_score(y_val, pred, average=i)\n",
    "        f1 = f1_score(y_val, pred, average=i)\n",
    "\n",
    "        print('üîª')\n",
    "        print(f'parameter : {i}')\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 Score:\", f1)\n",
    "        print()\n",
    "\n",
    "    print('='*50)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
