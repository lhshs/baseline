{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier            # Voting Í∏∞Î≤ï ÏÇ¨Ïö© Module\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value count & unique & Null Count\n",
    "df.info()\n",
    "print()\n",
    "print(df.isnull().sum() / len(df) * 100)\n",
    "print()\n",
    "\n",
    "for i in df.columns:\n",
    "    print('\\33[103m', i, '\\33[0m')\n",
    "    print(df[i].value_counts())\n",
    "    uu = str(df[i].unique())\n",
    "    print(df[i].dtype)\n",
    "    print('\\33[91m' + uu +  '\\033[0m')\n",
    "    print('\\33[94m' + 'Null Count :' + '\\033[0m', df[i].isnull().sum())\n",
    "    print('üåà')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object, float type Íµ¨Î∂Ñ \n",
    "type_lst = dict({'Object': [], 'Float64' : []})\n",
    "o_lst = []\n",
    "f_lst = []\n",
    "\n",
    "for i in dropout:\n",
    "    if dropout[i].dtype == 'O':\n",
    "        o_lst.append(i)\n",
    "    else:\n",
    "        f_lst.append(i)\n",
    "\n",
    "type_lst['Object'] = o_lst\n",
    "type_lst['Float64'] = f_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical plotly histogram\n",
    "\n",
    "cnt = -1\n",
    "\n",
    "for col in df_obj.columns:\n",
    "    cnt += 1\n",
    "    tt = ['title_names']\n",
    "    fig = px.histogram(df, x=col, text_auto=True, color_discrete_sequence=['chocolate'], width=800, height=400)\n",
    "    fig.update_layout(bargap=0.2, title=tt[cnt])\n",
    "    fig.show()\n",
    "\n",
    "#####\n",
    "\n",
    "# categorical histogram\n",
    "\n",
    "for col in df[['Sex', 'Ticket', 'Cabin', 'Embarked']].columns:\n",
    "    fig = sns.histplot(df, x=col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical plotly boxplot & describe\n",
    "\n",
    "cnt = -1\n",
    "\n",
    "for col in df_num.columns:\n",
    "    cnt += 1\n",
    "    tt = ['title_names']\n",
    "    fig = px.box(df, x=col, color_discrete_sequence=['maroon'], width=800, height=400)\n",
    "    fig.update_layout(bargap=0.2, title=tt[cnt])\n",
    "    fig.show()\n",
    "    print(df[a].describe())\n",
    "    print()\n",
    "    print('üëª')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≤∞Ï∏°Ïπò ÎπÑÏú®Î≥ÑÎ°ú ÎÑ£Í∏∞ \n",
    "import random\n",
    "\n",
    "ratio_fill = df.replace('X', np.NaN)   # To NaN\n",
    "\n",
    "nan_value = list(ratio_fill[ratio_fill[''].isnull()].index)                    # NaN Í∞í index \n",
    "select_nan_value = random.sample(nan_value, k=int(len(nan_value)*0.6))           # NaN Í∞íÏùò 60% ÏÑ†ÌÉù\n",
    "\n",
    "df.loc[fill_nan_value][['column_name']] = df.loc[fill_nan_value][['column_name']].fillna('M') \n",
    "df['column_name'] = df['column_name'].fillna('F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_TV</th>\n",
       "      <th>0_ÎÉâÏû•Í≥†</th>\n",
       "      <th>0_ÎØπÏÑú</th>\n",
       "      <th>0_ÏÑ†ÌíçÍ∏∞</th>\n",
       "      <th>0_Ï†ÑÏûêÎ†åÏßÄ</th>\n",
       "      <th>0_Ïª¥Ìì®ÌÑ∞</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_TV  0_ÎÉâÏû•Í≥†  0_ÎØπÏÑú  0_ÏÑ†ÌíçÍ∏∞  0_Ï†ÑÏûêÎ†åÏßÄ  0_Ïª¥Ìì®ÌÑ∞\n",
       "0     1      0     0      0       0      0\n",
       "1     0      1     0      0       0      0\n",
       "2     0      0     0      0       1      0\n",
       "3     0      0     0      0       0      1\n",
       "4     0      0     0      1       0      0\n",
       "5     0      0     0      1       0      0\n",
       "6     0      0     1      0       0      0\n",
       "7     0      0     1      0       0      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=['TV','ÎÉâÏû•Í≥†','Ï†ÑÏûêÎ†åÏßÄ','Ïª¥Ìì®ÌÑ∞','ÏÑ†ÌíçÍ∏∞','ÏÑ†ÌíçÍ∏∞','ÎØπÏÑú','ÎØπÏÑú']\n",
    "\n",
    "# Label Encoding\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(sample)\n",
    "\n",
    "# One-Hot Encoding\n",
    "# 2Ï∞®Ïõê ndarrayÎ°ú Î≥ÄÌôò ÌõÑ Ï†ÅÏö©\n",
    "items = np.array(sample).reshape(-1, 1)\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(sample)\n",
    "oh_labels = oh_encoder.transform(sample)\n",
    "# OneHotEncoderÎ°ú Î≥ÄÌôòÌïú Í≤∞Í≥ºÎäî Ìù¨ÏÜåÌñâÎ†¨(Sparse Matrix)Ïù¥ÎØÄÎ°ú toarray()Î•º Ïù¥Ïö©ÌïòÏó¨ Î∞ÄÏßë ÌñâÎ†¨(Dense Matrix)Î°ú Î≥ÄÌôò.\n",
    "oh_labels.toarray()\n",
    "\n",
    "# get_dummies\n",
    "df = pd.DataFrame(sample)\n",
    "pd.get_dummies(df, columns=[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \n",
    "y = \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=777)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train[num].columns:\n",
    "   # Standardization _ Standard\n",
    "   st_scaler = StandardScaler()\n",
    "   st_scaled = st_scaler.fit_transform(X_train[[col]])\n",
    "   X_train[[col]] = st_scaled\n",
    "\n",
    "   # Normalization _ MinMax\n",
    "   mm_scaler = MinMaxScaler()\n",
    "   mm_scaled = mm_scaler.fit_transform(X_train[[col]])\n",
    "   X_train[[col]] = mm_scaled\n",
    "\n",
    "   # Same Scaler to validation Data\n",
    "   st_scaled_t = st_scaler.transform(X_val[[col]])\n",
    "   X_val[[col]] = st_scaled_t\n",
    "   mm_scaled_t = mm_scaler.transform(X_val[[col]])\n",
    "   X_val[[col]] = mm_scaled_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance \n",
    "ftr_importances_values = 'modelname'.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns)\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "plt.show()\n",
    "\n",
    "# SHAP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Load\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "xgb = xgb.XGBClassifier()\n",
    "lgb = lgb.LGBMClassifier()\n",
    "\n",
    "# Training \n",
    "dt.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "dt_pred = dt.predict(X_val)\n",
    "rf_pred = rf.predict(X_val)\n",
    "xgb_pred = xgb.predict(X_val)\n",
    "lgb_pred = lgb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lst = ['Decision Tree', 'Random Forest', 'XGBoost', 'LightGBM']\n",
    "pred_lst = [dt_pred, rf_pred, xgb_pred, lgb_pred]\n",
    "parm = [None, 'micro', 'macro', 'weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, pred in zip(model_lst, pred_lst):\n",
    "    print('üîª','\\33[91m' + m + '\\033[0m', 'üîª')\n",
    "    accuracy = accuracy_score(y_val, pred)\n",
    "    precision = precision_score(y_val, pred)\n",
    "    recall = recall_score(y_val, pred)\n",
    "    f1 = f1_score(y_val, pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print()\n",
    "\n",
    "    print('='*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics average Ï∂îÍ∞Ä\n",
    "\n",
    "for m, pred in zip(model_lst, pred_lst):\n",
    "    print('\\33[91m' + m + '\\033[0m')\n",
    "    for i in parm:\n",
    "        accuracy = accuracy_score(y_val, pred)\n",
    "        precision = precision_score(y_val, pred, average=i)\n",
    "        recall = recall_score(y_val, pred, average=i)\n",
    "        f1 = f1_score(y_val, pred, average=i)\n",
    "\n",
    "        print('üîª')\n",
    "        print(f'parameter : {i}')\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 Score:\", f1)\n",
    "        print()\n",
    "\n",
    "    print('='*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'max_depth' : [4, 6, 8],\n",
    "                  'n_estimators': [50, 10],\n",
    "                  'max_features': ['sqrt', 'auto', 'log2'],\n",
    "                  'min_samples_split': [2, 3, 10],\n",
    "                  'min_samples_leaf': [1, 3, 10],\n",
    "                  'bootstrap': [True, False],\n",
    "                  }\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "grid_search = GridSearchCV(forest,\n",
    "                           scoring='accuracy',\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation,\n",
    "                           verbose=1\n",
    "                           )\n",
    "\n",
    "grid_search.fit(train, targets)\n",
    "model = grid_search\n",
    "parameters = grid_search.best_params_\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Voting\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Í∞úÎ≥Ñ Î™®Îç∏ÏùÄ KNNÏôÄ DecisionTree ÏûÑ\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m knn_clf \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m      4\u001b[0m dt_clf \u001b[39m=\u001b[39m DecisionTreeClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Í∞úÎ≥Ñ Î™®Îç∏ÏùÑ ÏÜåÌîÑÌä∏ Î≥¥ÌåÖ Í∏∞Î∞òÏùò ÏïôÏÉÅÎ∏î Î™®Îç∏Î°ú Íµ¨ÌòÑÌïú Î∂ÑÎ•òÍ∏∞\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Voting\n",
    "# Í∞úÎ≥Ñ Î™®Îç∏ÏùÄ KNNÏôÄ DecisionTree ÏûÑ\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Í∞úÎ≥Ñ Î™®Îç∏ÏùÑ ÏÜåÌîÑÌä∏ Î≥¥ÌåÖ Í∏∞Î∞òÏùò ÏïôÏÉÅÎ∏î Î™®Îç∏Î°ú Íµ¨ÌòÑÌïú Î∂ÑÎ•òÍ∏∞\n",
    "vo_clf = VotingClassifier(estimators=[('KNN', knn_clf),('DT', dt_clf)] , voting='hard')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy, recall, precision, auc graph, confusion matrix\n",
    "\n",
    "def eval_model(pred_list, name_list, y_test):\n",
    "    for pred, name in zip(pred_list, name_list):\n",
    "        accuracy = accuracy_score(y_test , pred)\n",
    "        recall = recall_score(y_test, pred)\n",
    "        precision = precision_score(y_test, pred)\n",
    "        auc = roc_auc_score(y_test, pred)\n",
    "        matrix = confusion_matrix(y_test, pred)\n",
    "\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        fpr, tpr, thresholds = roc_curve(y_val, pred, pos_label=1)\n",
    "        # roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, color='darkorange')\n",
    "        plt.plot([0, 1], [0, 1], color = 'black', label = 'y = x')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(matrix, annot=True, fmt='g') # fmt='g' : ÏßÄÏàò ÌëúÍ∏∞Î•º ÏùºÎ∞ò ÌëúÍ∏∞Î°ú\n",
    "        plt.title('{0} Model Confusion Matrix'.format(name))\n",
    "        plt.show()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        print('{0} Ï†ïÌôïÎèÑ: {1:.4f}'.format(name, accuracy))\n",
    "        print('{0} Recall: {1:.4f}'.format(name, recall))\n",
    "        print('{0} Precision: {1:.4f}'.format(name, precision))\n",
    "        print('{0} AUC: {1:.4f}'.format(name, auc))\n",
    "\n",
    "        print('='* 50)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
